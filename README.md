# IPC Benchmark: è¿›ç¨‹é—´é€šä¿¡æ€§èƒ½å¯¹æ¯”

ä½¿ç”¨ MPI æµ‹è¯•ä¸åŒ IPC (è¿›ç¨‹é—´é€šä¿¡) æ–¹æ¡ˆçš„æ€§èƒ½å¯¹æ¯”å·¥å…·ã€‚


## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ src/ipc_benchmark/
â”‚   â”œâ”€â”€ base.py              # æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ utils.py             # åºåˆ—åŒ–å·¥å…·
â”‚   â”œâ”€â”€ lmdb_backend.py      # LMDB å®ç°
â”‚   â”œâ”€â”€ shm_backend.py       # SharedMemory å®ç°
â”‚   â”œâ”€â”€ zmq_backend.py       # ZeroMQ å®ç°
â”‚   â”œâ”€â”€ mpi_backend.py       # MPI-Native å®ç°
â”‚   â””â”€â”€ mpi_pkl5_backend.py  # MPI-Pkl5 å®ç°ï¼ˆä¸æ¨èï¼‰
â”œâ”€â”€ benchmark_mpi.py         # MPI æµ‹è¯•ä¸»ç¨‹åº
â”œâ”€â”€ analyze_results.py       # ç»“æœåˆ†æ
â”œâ”€â”€ PERFORMANCE.md           # ğŸ“Š è¯¦ç»†æ€§èƒ½åˆ†æ
â”œâ”€â”€ pixi.toml                # Pixi ç¯å¢ƒé…ç½®
â””â”€â”€ README.md                # æœ¬æ–‡æ¡£
```

## å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…ä¾èµ–
pixi install

# è¿è¡Œ benchmark
pixi run bench              # æ ‡å‡†æµ‹è¯•ï¼ˆ1 writer + 3 readersï¼‰
pixi run bench-small        # å°è§„æ¨¡ï¼ˆ1 writer + 1 readerï¼‰
pixi run bench-large        # å¤§è§„æ¨¡ï¼ˆ1 writer + 7 readersï¼‰

# åˆ†æç»“æœ
pixi run analyze

# æŸ¥çœ‹è¯¦ç»†æ€§èƒ½åˆ†æ
cat PERFORMANCE.md
```

## Benchmark ç»“æœ

æµ‹è¯•ç¯å¢ƒ: **1 writer + 1 reader** (2ä¸ªMPIè¿›ç¨‹), 100æ¬¡è¯»å–è¿­ä»£, 10000 entries

### æ€§èƒ½å¯¹æ¯”

| Backend | å†™å…¥æ—¶é—´ | å•æ¬¡è¯»å– | æ¶æ„ç‰¹ç‚¹ |
|---------|---------|---------|---------|
| **LMDB** | 5.13ms | 5.89ms | æŒä¹…åŒ–å­˜å‚¨ |
| **SharedMemory** | 20.08ms | 5.97ms | æ ‡å‡†åº“ï¼Œé›¶æ‹·è´ |
| **ZeroMQ** | 570.85ms | 5.74ms | æ¶ˆæ¯ä¼ é€’ |
| **MPI-Native** | 577.34ms | 5.76ms | MPI é›†ä½“é€šä¿¡ |
| **MPI-Pkl5** | 603.46ms | 6.03ms | Pkl5 æ— ä¼˜åŠ¿ |

### æ ¸å¿ƒå‘ç°

#### è¯»å–æ€§èƒ½ï¼šæ‰€æœ‰æ–¹æ¡ˆç›¸è¿‘ï¼ˆ< 5%ï¼‰
- ååºåˆ—åŒ–æ˜¯ä¸»è¦ç“¶é¢ˆ
- ä¼ è¾“æœºåˆ¶å·®å¼‚å¯å¿½ç•¥ä¸è®¡

#### å†™å…¥æ€§èƒ½ï¼šæ¶æ„å·®å¼‚æ˜¾è‘—

**å…±äº«å­˜å‚¨æ¨¡å‹ï¼ˆLMDBã€SharedMemoryï¼‰**
- å†™ä¸€æ¬¡ï¼Œå¤šæ¬¡è¯»å–
- å†™å…¥é€Ÿåº¦ä¸å— reader æ•°é‡/è¿­ä»£æ¬¡æ•°å½±å“
- âœ… é€‚åˆå¤š reader å¹¶å‘åœºæ™¯

**æ¶ˆæ¯ä¼ é€’æ¨¡å‹ï¼ˆZeroMQã€MPIï¼‰**
- æ¯æ¬¡è¯»å–éœ€å•ç‹¬å‘é€æ¶ˆæ¯
- å†™å…¥æ—¶é—´ = readeræ•°é‡ Ã— è¿­ä»£æ¬¡æ•° Ã— å•æ¡æ¶ˆæ¯æ—¶é—´
- âœ… é€‚åˆå• reader æµå¼ä¼ è¾“

ğŸ“Š **è¯¦ç»†åˆ†æ** â†’ [PERFORMANCE.md](./PERFORMANCE.md)

## ä½¿ç”¨å»ºè®®

**æ ¹æ®åŠŸèƒ½éœ€æ±‚é€‰æ‹©ï¼š**

| Backend | æ¨èåœºæ™¯ | å…³é”®ç‰¹æ€§ |
|---------|---------|---------|
| **LMDB** | éœ€è¦æŒä¹…åŒ– | å”¯ä¸€æ”¯æŒæŒä¹…åŒ–ï¼ŒACID äº‹åŠ¡ |
| **SharedMemory** | æ— å¤–éƒ¨ä¾èµ– | Python æ ‡å‡†åº“ï¼Œå¤š reader é«˜æ•ˆ |
| **MPI-Native** | HPC/åˆ†å¸ƒå¼ | è·¨èŠ‚ç‚¹é€šä¿¡ï¼Œå·²æœ‰ MPI ç¯å¢ƒ |
| **ZeroMQ** | æµå¼ä¼ è¾“ | çµæ´»é€šä¿¡æ¨¡å¼ï¼Œå• reader åœºæ™¯ |
| ~~MPI-Pkl5~~ | âŒ ä¸æ¨è | æ— æ€§èƒ½ä¼˜åŠ¿ï¼Œå¢åŠ å¤æ‚åº¦ |

## æ•…éšœæ’é™¤

```bash
# æ¸…ç†æ®‹ç•™æ–‡ä»¶
pixi run clean

# æµ‹è¯• MPI ç¯å¢ƒ
pixi run mpiexec --version
```
